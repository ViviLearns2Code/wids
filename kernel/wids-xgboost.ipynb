{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIDS 2018 Datathon\n",
    "\n",
    "The dataset for the challenge will contain demographic and behavioral information from a representative sample of survey respondents from India and their usage of traditional and mobile financial services. The dataset is a product of InterMedia’s research to help the world’s poorest people take advantage of widely available mobile phones and other digital technology to access financial tools and participate more fully in their local economies. Women in these communities, in particular, are often largely excluded from the formal financial system. By predicting gender, the datathon teams will explore the key differences in behavior patterns of men and women, and how that may impact their use of new financial services. Ideally, these findings will influence plans to reach women in developing economies and encourage them to adopt new financial tools that will help to lift them and their families out of poverty.\n",
    "\n",
    "## Data\n",
    "The training set has 18255 entries with 1235 features.\n",
    "The test set has 27285 entries with 1234 features.\n",
    "Both datasets have the same columns except for \n",
    "* test_id and train_id\n",
    "* the additional column is_female in the training set (which is our target value)\n",
    "\n",
    "All columns represent different answers to survey questions. The columns suffixed \"OTHERS\" contain answers which are not included as answering options in the respective survey question. In the respective survey question, this freestyle answer is encoded as \"96 - others\". We can therefore drop all \"OTHERS\" columns, as the information we need is already contained in the column of the respective question. The same applies to the columns \"MM12_REC\" and \"MM13_REC\", which contain freestyle answers.\n",
    "The only other text columns are LN2_RIndLngBEOth and LN2_WIndLngBEOth. Survey questions LN2_3 and LN2_4 were conducted in different languages. The language name is recorded in LN2_RIndLngBEOth and LN2_WIndLngBEOth. These specifications were also noted down in a freestyle fashion (for example, language combinations such as \"Hindi & Rajasthani\" or typos such as \"HIndi\"). We drop the columns and only use LN2_3 and LN2_4 without further specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv', low_memory=False)\n",
    "train = pd.read_csv('../input/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LN2_RIndLngBEOth.value_counts()\n",
    "train.LN2_RIndLngBEOth.isnull().sum()\n",
    "np.setdiff1d(test.LN2_RIndLngBEOth.values.tolist(), train.LN2_RIndLngBEOth.values.tolist())\n",
    "\n",
    "train.LN2_WIndLngBEOth.value_counts()\n",
    "np.setdiff1d(test.LN2_WIndLngBEOth.values.tolist(), train.LN2_WIndLngBEOth.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(list(train.filter(regex = 'OTHERS')), axis = 1, inplace = True)\n",
    "train.drop(['MM13_REC','MM12_REC'],axis=1,inplace=True)\n",
    "train.drop(['LN2_RIndLngBEOth','LN2_WIndLngBEOth'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(list(test.filter(regex = 'OTHERS')), axis = 1, inplace = True)\n",
    "test.drop(['MM13_REC','MM12_REC'],axis=1,inplace=True)\n",
    "test.drop(['LN2_RIndLngBEOth','LN2_WIndLngBEOth'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.is_female.sum()/np.shape(train)[0] # training set is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost \n",
    "\n",
    "XGBoost is a Gradient Boosting Machine which can automatically deal with missing values by learning default directions at each node (https://arxiv.org/abs/1603.02754). No further preprocessing is necessary.\n",
    "We use the scikit-learn wrapper for XGBoost to use scikit-learn's GridSearchCV for hyperparameter tuning.\n",
    "\n",
    "For the submission, we used max_depth=8, min_child_weight=3, n_estimators=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth': [8],\n",
    "    'min_child_weight': [3]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, gamma=0.9, n_estimators=200, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', nthread=10, seed=0),\n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=3, return_train_score=True, refit=True)\n",
    "gsearch1.fit(train.drop(['train_id','is_female'],axis=1),train['is_female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xgb=gsearch1.predict_proba(test.drop(['test_id'],axis=1))[:,1]\n",
    "#pd.DataFrame(result_xgb).to_csv('results_xgb_all_grid.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(learning_rate=0.1, gamma=0.9, n_estimators=200, subsample=0.8, colsample_bytree=0.8,\n",
    "                        max_depth=8, min_child_weight=3, objective= 'binary:logistic', nthread=10, seed=0)\n",
    "xgb_clf.fit(train.drop(['train_id','is_female'],axis=1),train['is_female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=xgb_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(importances)[::-1]\n",
    "sort_idx\n",
    "print(importances[sort_idx])\n",
    "np.where(importances[sort_idx]>0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['train_id','is_female'],axis=1).columns[sort_idx[1:25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are no clear gender-defining features, because the scores are very close to zero. The most important questions seem to be\n",
    "* DL1. In the past 12 months, were you mainly...?\n",
    "* AA7. Unknown\n",
    "* DG3. Marital Status\n",
    "* AA14. Unknown\n",
    "* DL2. Primary Job\n",
    "* DG6.How are you related to the household head? \n",
    "* DG4. What is your highest level of education?\n",
    "* FB20.What is the main reason you do not borrow from a bank?\n",
    "* FL9B.Imagine that this month, after paying for food, cooking fuel, school fees, rent, and airtime, you found yourself with some extra money. Please, select 3 options from the list that you are most likely to spend it on. Option 2\n",
    "* MT1A.Who decides on who should have a phone in your household?\n",
    "* AA15. Unknown\n",
    "* DL5. You have said that these are the ways you got money in the past 12 months. Which of these brought you the most money?\n",
    "* FF3. What is the main reason you do not have a bank account?\n",
    "* IFI24. What is the main reason you do not belong to any informal societies or group saving schemes?\n",
    "* FL9C. Imagine that this month, after paying for food, cooking fuel, school fees, rent, and airtime, you found yourself with some extra money. Please, select 3 options from the list that you are most likely to spend it on. Option 3\n",
    "* DL8. How much of your land is under cultivation? Unit: Acres (99=DK)\n",
    "* DL15. What is the highest grade that the female head/spouse completed? \n",
    "* IFI16_1. If you want to get to Over the counter in a branch of a bank , how would you get there? Would you…? \n",
    "* GN1. Who usually decides how the money you earn will be used?\n",
    "* FL10. What’s the most important financial goal for you right now?\n",
    "* DG8a. How many adults and children do you have in the household? (99 for DK): Number of adults\n",
    "* MT9. What is the main reason you do not have a mobile phone and do not use somebody else’s mobile phone?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to self: Read Section 10.13.1 “Relative Importance of Predictor Variables” in The Elements of Statistical Learning\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

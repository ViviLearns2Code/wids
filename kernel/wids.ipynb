{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIDS 2018 Datathon\n",
    "\n",
    "The dataset for the challenge will contain demographic and behavioral information from a representative sample of survey respondents from India and their usage of traditional and mobile financial services. The dataset is a product of InterMedia’s research to help the world’s poorest people take advantage of widely available mobile phones and other digital technology to access financial tools and participate more fully in their local economies. Women in these communities, in particular, are often largely excluded from the formal financial system. By predicting gender, the datathon teams will explore the key differences in behavior patterns of men and women, and how that may impact their use of new financial services. Ideally, these findings will influence plans to reach women in developing economies and encourage them to adopt new financial tools that will help to lift them and their families out of poverty.\n",
    "\n",
    "## Goal\n",
    "For each test_id in the test set, you must predict a probability for the person being female\n",
    "\n",
    "## Data\n",
    "The training set has 18255 entries with 1235 features.\n",
    "The test set has 27285 entries with 1234 features.\n",
    "Both datasets have the same columns except for \n",
    "* test_id and train_id\n",
    "* the additional column is_female in the training set (which is our target value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv', low_memory=False)\n",
    "train = pd.read_csv('../input/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test size\", test.shape)\n",
    "print(\"Train size\", train.shape)\n",
    "test_headers = test.columns.values.tolist()\n",
    "train_headers = train.columns.values.tolist()\n",
    "combined = train.append(test)\n",
    "print(\"Combined size\", combined.shape)\n",
    "print(\"Column differences\", np.setdiff1d(train_headers, test_headers), np.setdiff1d(test_headers,train_headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "First, we will take a look at the train and test data. If we look at the data dictionary excel file, we can see that all columns are of categorical (or at least integer) nature and that most of them are encoded answers to interview questions. \n",
    "\n",
    "To preprocess the large amount of data in a meaningful way, we first drop columns with more than 75% missing data and the columns which most likely describe interview circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\n",
    "X_test = test\n",
    "y_train = train.is_female\n",
    "\n",
    "X_train.drop(['AA4', 'AA5', 'AA6', 'AA7', 'AA14', 'AA15'], axis=1, inplace=True)\n",
    "X_train.dropna(thresh=0.75*len(X_train), axis=1, inplace=True)\n",
    "X_train.drop(['train_id', 'is_female'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Remaining columns:\", np.size(X_train.columns.values.tolist()))\n",
    "\n",
    "X_test = X_test[X_train.columns.values.tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, for example, that columns encoding answers for \"OTHERS\" were dropped. Out of the remaining columns, some are still missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indices_nan = np.array(np.where(X_train.isnull().sum()>0))[0] # indices of columns with missing values\n",
    "print(\"Number of columns with missing values\", np.size(col_indices_nan)) \n",
    "X_headers_nan = [X_train.columns.values.tolist()[i] for i in col_indices_nan] # labels of columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start imputing the missing values, we check the nature of the remaining columns. All columns have integer values which could be interpreted as both nominal (e.g. Yes/No) or ordinal data (\"On a scale from 1 to 4...\"). Every categorical column can also have a different number of possible values. \n",
    "\n",
    "Columns with many unique values have a high probability of being ordinal variables.\n",
    "* DG1: Year of birth **(ordinal)**\n",
    "* FB13: How many times in the past 12 months have you borrowed money (from outside your household)? **(ordinal)**\n",
    "* DL14: Unknown\n",
    "* FL4: What or who do you depend on the most for financial advice? (nominal)\n",
    "* DL11: In the past 12 months,how many times did you move from one home to another? **(ordinal)**\n",
    "* FB20: What is the main reason you do not borrow from a bank? (nominal)\n",
    "* MT1: How many people in your household have a mobile phone? **(ordinal)**\n",
    "* DG8a - DG8c, DG9a - DG9c: How many... **(ordinal)**\n",
    "* FL10: What’s the most important financial goal for you right now? (nominal)\n",
    "* DG4: What is your highest level of education? **(ordinal or nominal)**\n",
    "* FL9A: Imagine that this month, after paying for food, cooking fuel, school fees, rent, and airtime, you found yourself with some extra money. Please, select 3 options from the list that you are most likely to spend it on, Option 1. (nominal)\n",
    "* DL1: In the past 12 months, were you mainly...? (nominal)\n",
    "* FL9B: Imagine that this month, after paying for food, cooking fuel, school fees, rent, and airtime, you found yourself with some extra money. Please, select 3 options from the list that you are most likely to spend it on, Option 2. (nominal)\n",
    "* FB19: Which of the following best describes how you spent the money you borrowed last time? (nominal)\n",
    "* IFI16_1: If you want to get to Over the counter in a branch of a bank , how would you get there? Would you…? (nominal)\n",
    "* DG3: What is your marital status? (nominal)\n",
    "* DG6: How are you related to the household head? (nominal)\n",
    "* IFI18: How many informal societies or group saving schemes do you use or personally belong to? **(ordinal)**\n",
    "* DG3A: What is your religion? (nominal)\n",
    "* IFI14_1 - IFI14_7: How close... **(ordinal)**\n",
    "* IFI15_1 - IFI15_7: How much time... **(ordinal)**\n",
    "* MT1A: Who decides on who should have a phone in your household? (nominal)\n",
    "* DL24: Please look at this card and tell me which answer best reflects your family's financial situation? (nominal)\n",
    "* IFI17_1 - IFI17-7: On a scale... **(ordinal)**\n",
    "* GN1 - GN5: Who decides... (nominal)\n",
    "* FL8_1 - FL8_7: How much do you agree with ... **(ordinal)**\n",
    "* FL11: How likely is it that you could get together sufficient funds from your friends and family for a medical emergency if it was too much for you to manage alone? **(ordinal)**\n",
    "* FB18: Which of the following statements best describes how you usually repay your loans? (nominal)\n",
    "* LN2_1 - LN2_4: On a scale... **(ordinal)**\n",
    "* FL8_1 - FL8_7: How much do you agree... **(ordinal)**\n",
    "* DL15: What is the highest grade that the female head/spouse completed? **(ordinal or nominal)**\n",
    "* FL1: How often do you make a plan for how to manage your money, whether it is earned through a job, received from the government or from other people? **(ordinal)**\n",
    "* FL15: Suppose over the next 10 years the prices of the things you buy double. If your income also doubles, will you be able to buy less than you can buy today, the same as you can buy today, or more than you can buy today? (nominal, it is a quiz answer)\n",
    "* AA3: Zone (nominal)\n",
    "* LN1A, LN1B: Literacy **(ordinal)**\n",
    "* All other columns have less than or equal to 3 unique values, which we will take as being nominal\n",
    "\n",
    "Ordinal columns will not be one-hot encoded later on. This means that we need to deal with the placeholder value 99 which is used to encode the answering option \"Don't know\". Otherwise the value distorts ordinal relationships. We will therefore replace both missing values and the value 99 with the median value in ordinal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns with the most unique values\")\n",
    "print(X_train.apply(pd.Series.nunique).sort_values(axis=0,ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column DG1 represents birth years. We will create a new age column which assigns each sample to an age bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinCreator:\n",
    "    def __init__(self,colSeries):\n",
    "        self.quantiles=colSeries.quantile([.25, .5, .75]).values\n",
    "    def assignBin(self, x):\n",
    "        if x <= self.quantiles[0]:\n",
    "            return 1\n",
    "        if x <= self.quantiles[1]:\n",
    "            return 2\n",
    "        if x <= self.quantiles[2]:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "\n",
    "X_test.DG1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply agebin transformation to training and test set\n",
    "ageBinCreator = BinCreator(X_train.DG1)\n",
    "X_train.loc[:,'agebin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DG1'])\n",
    "X_test.loc[:,'agebin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DG1'])\n",
    "\n",
    "# drop the original DG1 column\n",
    "X_train = X_train.drop(['DG1'], axis=1) \n",
    "X_test = X_test.drop(['DG1'], axis=1)\n",
    "X_test.agebin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other ordinal columns, we will replace the placeholder value 99 with NaN first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = [\n",
    "    'agebin', 'MT1bin', 'DG8abin', 'DG8bbin', 'DG8cbin', 'DG9abin', 'FB13', 'DL14', 'DL11'\n",
    "    'FL8_1', 'FL8_2','FL8_3','FL8_4','FL8_5','FL8_6','FL8_7',\n",
    "    'LN2_1','LN2_2','LN2_3','LN2_4',\n",
    "    'MM42_1', 'MM42_2', 'MM42_3', 'MM42_4', 'MM42_5', 'MM42_6',\n",
    "    'MM32_1', 'MM32_2', 'MM32_3', 'MM32_4', 'MM32_5', 'MM32_6', 'MM32_7', 'MM32_8', 'MM32_9', 'MM32_10','MM32_11', 'MM32_12', 'MM32_13', \n",
    "    'IFI17_1', 'IFI17_2', 'IFI17_3', 'IFI17_4', 'IFI17_5', 'IFI17_6', 'IFI17_7',\n",
    "    'LN1B', 'LN1A',\n",
    "    'RI6_1', 'RI6_2', 'RI6_3', 'RI7_1', 'RI7_2', 'RI7_3',\n",
    "    'FB13',\n",
    "    'DL14',\n",
    "    'DL11',\n",
    "    'MT1',\n",
    "    'DG8a', 'DG8b', 'DG8c', 'DG9a', 'DG9b', 'DG9c',\n",
    "    'IFI18'\n",
    "]\n",
    "intersect = np.intersect1d(ordinal,X_train.columns.values.tolist(),assume_unique=True)\n",
    "X_train.loc[:,intersect] = X_train[intersect].replace(to_replace=[99],value=[np.nan],inplace=False)\n",
    "\n",
    "# do the same for test set\n",
    "X_test.loc[:,intersect] = X_test[intersect].replace(to_replace=[99],value=[np.nan],inplace=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(thresh=0.75*len(X_train), axis=1, inplace=True)\n",
    "print(\"Remaining columns:\",np.size(X_train.columns.values.tolist()))\n",
    "\n",
    "X_test=X_test[X_train.columns.values.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing all 99 (Don't know) with NaN in both train and test sets and dropping all resulting columns with more than 25% missing values, we can impute the missing values for the ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = np.intersect1d(ordinal,X_train.columns.values.tolist(),assume_unique=True)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "imp.fit(X_train[intersect])\n",
    "\n",
    "# train set\n",
    "X_train[intersect]=imp.transform(X_train[intersect])\n",
    "\n",
    "# test set\n",
    "X_test[intersect] = imp.transform(X_test[intersect])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we impute the missing nominal values with the column mode. We can leave 99 as its own category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal = np.setdiff1d(X_train.columns.values.tolist(), ordinal)\n",
    "\n",
    "imp_nom = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "imp_nom.fit(X_train[nominal])\n",
    "\n",
    "# train set\n",
    "X_train[nominal] = imp_nom.transform(X_train[nominal])\n",
    "X_train.head()\n",
    "\n",
    "# test set\n",
    "X_test[nominal] = imp_nom.transform(X_test[nominal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert all column types to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert float to int\n",
    "numeric = X_train.select_dtypes(include=np.number).columns\n",
    "non_numeric = train.select_dtypes(exclude=np.number).columns # _OTHERS columns\n",
    "print(\"Numeric columns\", np.size(numeric))\n",
    "print(\"Other columns\", np.size(non_numeric))\n",
    "\n",
    "X_train[numeric]=X_train[numeric].astype(int)\n",
    "X_test[numeric]=X_test[numeric].astype(int)\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created age bins based on age quantiles of the training set. The columns FB13, DL14, DL11, MT1, DG8a- DG8c, DG9a - DG9c and IFI18 (DG9b, DG9c, IFI18 were dropped already) still have many levels (>12) and are not binned by default. We will group them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'FB13bin'] = np.vectorize(ageBinCreator.assignBin)(X_train['FB13'])\n",
    "X_test.loc[:,'FB13bin'] = np.vectorize(ageBinCreator.assignBin)(X_test['FB13'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'DL14bin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DL14'])\n",
    "X_test.loc[:,'DL14bin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DL14'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'DL11bin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DL11'])\n",
    "X_test.loc[:,'DL11bin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DL11'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'MT1bin'] = np.vectorize(ageBinCreator.assignBin)(X_train['MT1'])\n",
    "X_test.loc[:,'MT1bin'] = np.vectorize(ageBinCreator.assignBin)(X_test['MT1'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'DG8abin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DG8a'])\n",
    "X_test.loc[:,'DG8abin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DG8a'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'DG8bbin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DG8b'])\n",
    "X_test.loc[:,'DG8bbin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DG8b'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'DG8cbin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DG8c'])\n",
    "X_test.loc[:,'DG8cbin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DG8c'])\n",
    "\n",
    "FB13BinCreator = BinCreator(X_train.FB13)\n",
    "X_train.loc[:,'DG9abin'] = np.vectorize(ageBinCreator.assignBin)(X_train['DG9a'])\n",
    "X_test.loc[:,'DG9abin'] = np.vectorize(ageBinCreator.assignBin)(X_test['DG9a'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['FB13'], axis=1) \n",
    "X_test = X_test.drop(['FB13'], axis=1)\n",
    "X_train = X_train.drop(['DL14'], axis=1) \n",
    "X_test = X_test.drop(['DL14'], axis=1)\n",
    "X_train = X_train.drop(['DL11'], axis=1) \n",
    "X_test = X_test.drop(['DL11'], axis=1)\n",
    "X_train = X_train.drop(['MT1'], axis=1) \n",
    "X_test = X_test.drop(['MT1'], axis=1)\n",
    "X_train = X_train.drop(['DG8a'], axis=1) \n",
    "X_test = X_test.drop(['DG8a'], axis=1)\n",
    "X_train = X_train.drop(['DG8b'], axis=1) \n",
    "X_test = X_test.drop(['DG8b'], axis=1)\n",
    "X_train = X_train.drop(['DG8c'], axis=1) \n",
    "X_test = X_test.drop(['DG8c'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode the nominal columns. A custom encoder needs to be written because scikit-learn's standard one-hot encoder turns all integers between [min(column), max(column)] into categories. In our dataset however, the number of categories (=answering options) is mostly lower than 10, but the integer value 99 acts as placeholder for the answering option \"Don't know\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOneHot(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = []\n",
    "\n",
    "    def transform(self, X):\n",
    "        encoded = pd.get_dummies(X, columns=self.columns, prefix=self.columns)\n",
    "        return encoded\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.columns = X.columns.values.tolist()\n",
    "\n",
    "X_train.head()\n",
    "nominal = np.setdiff1d(X_train.columns.values.tolist(), ordinal)\n",
    "onehot = CustomOneHot()\n",
    "onehot.fit(X_train[nominal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = onehot.transform(X_train)\n",
    "X_test = onehot.transform(X_test)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on chi squared test, we choose 140 features with the strongest correlation to the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformA=SelectKBest(chi2, k=140).fit(X_train, y_train)\n",
    "supportA_index = np.array(np.where(transformA.get_support()==True))[0]\n",
    "labelsA = [X_train.columns.values.tolist()[i] for i in supportA_index]\n",
    "labels = labelsA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "The goal of this project is to get familiar with different models and then to combine suitable models in an ensemble.\n",
    "\n",
    "### Logistic Regression\n",
    "We can now train several models to see how well a single model can perform. We start with logistic regression and search for the best regularization parameter C with LogisticRegressionCV which is faster than GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegressionCV(Cs=[0.01, 0.03, 0.1, 0.3, 1, 3], scoring='roc_auc', cv=3, penalty='l1', random_state=0, refit=True, solver='liblinear')\n",
    "log_clf.fit(X_train[labels], y_train)\n",
    "log_clf.scores_, log_clf.C_ # best: C=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = log_clf.predict_proba(X_test[labels])[:,1]\n",
    "#pd.DataFrame(result_log).to_csv('results_log.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of features does not seem to increase the score much. The validation score is only 95.9, but the difference between validation and training score is below 0.5, which means that this model doesn't have an overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "It turns out that SVM performance is very bad with a dataset of such high dimensions.\n",
    "LinearSVR (SVM with a linear kernel) is very inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees\n",
    "Gradient Boosted Trees with xgboost is the most performant. We notice that without any data preprocessing, the algorithm can reach a score of about 97% (see `wids-xgboost.ipynb`). With preprocessing, xgboost does not perform better. This could hint to suboptimal preprocessing such as the handling of missing errors or the encoding of categorical data. Scikit-learn's GradientBoostingClassifier performs equally well, but needs more computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT with scikit-learn\n",
    "param_gb = {\n",
    "    'n_estimators': [200], \n",
    "    'learning_rate': [0.1], \n",
    "    'max_depth': [5, 6, 7],\n",
    "    'random_state': [0]\n",
    "}\n",
    "gb_clf = GridSearchCV(GradientBoostingClassifier(), param_grid=param_gb, cv=3, scoring='roc_auc')\n",
    "gb_clf.fit(X_train[labels], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.grid_scores_, gb_clf.best_params_ #max_depth: 5, learning_rate: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=0)\n",
    "gb_clf.fit(X_train[labels], y_train)\n",
    "result_gb = gb_clf.predict_proba(X_test[labels])[:,1]\n",
    "#pd.DataFrame(result_gb).to_csv('results_gb.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important = np.argsort(gb_clf.feature_importances_)[-10:]\n",
    "np.asarray(labels)[most_important]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "param_xgb = {\n",
    "    'max_depth': list(range(5,8,1)),\n",
    "    'min_child_weight': list([1,2]),\n",
    "}\n",
    "xgb_clf = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=200, \n",
    "                                                 gamma=0.9, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                 objective= 'binary:logistic', nthread=5, seed=0),\n",
    "                        param_grid = param_xgb, scoring='roc_auc',n_jobs=4,iid=False, cv=3)\n",
    "xgb_clf.fit(X_train[labels], y_train)\n",
    "xgb_clf.grid_scores_, xgb_clf.best_params_, xgb_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xgb = xgb_clf.predict_proba(X_test[labels])[:,1]\n",
    "#pd.DataFrame(result_xgb).to_csv('results_xgb_1.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important = np.argsort(xgb_clf.best_estimator_.feature_importances_)[-10:]\n",
    "np.asarray(labels)[most_important]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Trees\n",
    "Instead of combining several weak learners to one powerful model, random forest trees use several powerful learners to mitigate variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rft={\n",
    "    'n_estimators': [150],\n",
    "    'max_depth': [20],\n",
    "    'random_state': [0]\n",
    "}\n",
    "rft = GridSearchCV(estimator=RandomForestClassifier(),param_grid=param_rft, cv=3, scoring='roc_auc')\n",
    "rft.fit(X_train[labels], y_train)\n",
    "rft.grid_scores_, rft.best_params_, rft.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rft = rft.predict_proba(X_test[labels])[:,1]\n",
    "#pd.DataFrame(result_rft).to_csv('results_rft.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "We use PyTorch as the framework for constructing neural network. For this binary classification problem, we use a single hidden layer with ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=SelectKBest(chi2, k=500).fit(X_train, y_train)\n",
    "support_index = np.array(np.where(transform.get_support()==True))[0]\n",
    "labels = [X_train.columns.values.tolist()[i] for i in support_index]\n",
    "\n",
    "M = np.shape(X_train[labels])[1] #number of features\n",
    "H = 250 #number of hidden units\n",
    "O = 2 #number of categories\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        # 1 hidden layer, 2 output categories\n",
    "        self.hidden = nn.Linear(dim_in, dim_hidden)\n",
    "        self.out = nn.Linear(dim_hidden, dim_out)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "nn_clf = NNClassifier(M,H,O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E=200\n",
    "\n",
    "nn_X = X_train[labels].values\n",
    "nn_y = y_train.values\n",
    "# divide into train and validation set\n",
    "nn_X_train, nn_X_val, nn_y_train, nn_y_val = train_test_split(nn_X, nn_y, test_size=0.20)\n",
    "\n",
    "input = Variable(torch.from_numpy(nn_X_train).float())\n",
    "target = Variable(torch.from_numpy(nn_y_train), requires_grad=False)\n",
    "\n",
    "optimizer = optim.SGD(nn_clf.parameters(),  lr = 0.01, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[350,500], gamma=0.1)\n",
    "for epoch in range(E):\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    nn_clf.train(mode=True)\n",
    "    output = nn_clf(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.data)\n",
    "# train\n",
    "nn_prob_train = np.exp(output.data.numpy())\n",
    "nn_roc_auc_train = roc_auc_score(y_true=target.data, y_score=nn_prob_train[:,1])\n",
    "    \n",
    "# validation\n",
    "input_val = Variable(torch.from_numpy(nn_X_val).float())\n",
    "target_val = Variable(torch.from_numpy(nn_y_val).long(), requires_grad=False)\n",
    "nn_clf.eval()\n",
    "output_val = nn_clf(input_val)\n",
    " \n",
    "nn_prob_val = np.exp(output_val.data.numpy())\n",
    "nn_roc_auc_val = roc_auc_score(y_true=target_val.data, y_score=nn_prob_val[:,1])\n",
    "\n",
    "print(\"Validation ROC-AUC\",nn_roc_auc_val)\n",
    "print(\"Training ROC-AUC\",nn_roc_auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "input_test = Variable(torch.from_numpy(X_test[labels].values).float())\n",
    "nn_clf.eval()\n",
    "output_test = nn_clf(input_test)\n",
    "nn_prob_test = np.exp(output_test.data.numpy())[:,1]\n",
    "#pd.DataFrame(nn_prob_test).to_csv('results_nn.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier\n",
    "We stack 3 models with a voting classifier. The voting classifier does not perform better than its best components alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformA=SelectKBest(chi2, k=140).fit(X_train, y_train)\n",
    "support_indexA = np.array(np.where(transformA.get_support()==True))[0]\n",
    "labelsA = [X_train.columns.values.tolist()[i] for i in support_indexA]\n",
    "\n",
    "labels = labelsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_stack = {\n",
    "    'weights': [\n",
    "        [0.2, 0.3, 0.5]\n",
    "    ],\n",
    "    'log_clf__C': [1],\n",
    "    'xgb_clf__learning_rate': [0.03],\n",
    "    'xgb_clf__n_estimators': [200],\n",
    "    'xgb_clf__gamma': [0.9],\n",
    "    'xgb_clf__subsample': [0.8],\n",
    "    'xgb_clf__max_depth': [8],\n",
    "    'xgb_clf__min_child_weight': [1],\n",
    "    'xgb_clf__colsample_bytree': [0.8],\n",
    "    'rft_clf__n_estimators': [200],\n",
    "    'rft_clf__max_depth': [25]\n",
    "}\n",
    "estimators = [\n",
    "    ('log_clf', LogisticRegression(random_state=0)), \n",
    "    ('rft_clf', RandomForestClassifier(random_state=0, n_jobs = -1)), \n",
    "    ('xgb_clf', XGBClassifier(objective='binary:logistic', nthread=5, seed=0))\n",
    "]\n",
    "stack_clf = GridSearchCV(VotingClassifier(estimators, voting='soft', n_jobs=1, flatten_transform=None), param_grid=param_stack, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_clf.fit(X_train[labels], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_clf.grid_scores_, stack_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VotingClassifier(estimators=estimators).get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_stack = stack_clf.predict_proba(X_test[labels])[:,1]\n",
    "#pd.DataFrame(result_stack).to_csv('results_voting.csv',index=True, index_label='test_id', header = [\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
